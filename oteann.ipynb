{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OTEANN with Transformers\n",
    "\n",
    "This notebook investigates the orthographic depth of some spelling systems.\n",
    "\n",
    "This is a new version of OTEANN, which is now implemented with a GPT model instead of a Seq2Seq.\n",
    "\n",
    "The code used in this pages mainly comes from https://github.com/karpathy/minGPT (under MIT licence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up logging\n",
    "import logging\n",
    "logging.basicConfig(\n",
    "        format=\"%(asctime)s - %(levelname)s - %(name)s -   %(message)s\",\n",
    "        datefmt=\"%m/%d/%Y %H:%M:%S\",\n",
    "        level=logging.ERROR,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "from mingpt.model import GPT, GPTConfig\n",
    "from mingpt.trainer import Trainer, TrainerConfig\n",
    "from mingpt.utils import sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make deterministic\n",
    "#from mingpt.utils import set_seed\n",
    "#set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'episodes': 1, 'n_train': 10000, 'n_layer': 4, 'n_head': 4, 'n_embd': 352, 'batch_size': 256}\n"
     ]
    }
   ],
   "source": [
    "# These first configuration parameters are hyperparameters that we will need to tune\n",
    "CONFIG = {            \n",
    "    'episodes': 1,\n",
    "    'n_train': 10000,\n",
    "    'n_layer': 4,\n",
    "    'n_head': 4,\n",
    "    'n_embd': 352,\n",
    "    'batch_size': 256\n",
    "}\n",
    "print(CONFIG)\n",
    "ROOT_DIR = os.getcwd()\n",
    "\n",
    "# These other configuration parameters will not be tuned\n",
    "def extend_config(config): \n",
    "    config['languages'] = ['ent', 'eno', 'ar', 'br', 'de', \n",
    "                           'en', 'eo', 'es', 'fi', 'fr', \n",
    "                           'fro', 'it', 'ko', 'nl', 'pt', \n",
    "                           'ru', 'sh', 'tr', 'zh']\n",
    "    config['languages'] = ['sh']\n",
    "    config['n_test'] = 1000\n",
    "    config['print_predictions_ko'] = False\n",
    "    config['print_predictions_ok'] = False\n",
    "    config['print_test_results'] = True\n",
    "    config['do_finetune'] = False\n",
    "    config['n_samples'] = config['n_train'] + config['n_test']\n",
    "    config['label'] = 'oteann' + '_' + str(config['n_samples'])\n",
    "    config['root_dir'] = ROOT_DIR    \n",
    "    config['output_max_len'] = 25\n",
    "    config['block_size'] = 63\n",
    "    config['do_train'] = True  # allows skipping training between multiple re-runs\n",
    "    config['tasks'] = ['write', 'read']\n",
    "    config['subdatasets_dir'] = 'subdatasets'\n",
    "    config['sep'] = ','\n",
    "    config['features'] =  ['Language', 'Task', 'Input', 'Output']    \n",
    "    config['trial_dir'] = os.getcwd()\n",
    "    config['trial_filename'] = config['trial_dir'] + '/' + config['label']\n",
    "    config['subdataset'] = 'wikt_samples.csv' # postfix from fonetik.fr's files \n",
    "    config['train_filename'] = config['trial_filename'] + '_train.csv'\n",
    "    config['test_filename'] = config['trial_filename'] + '_test.csv'\n",
    "    config['model_filename'] = config['trial_filename'] + '_model.pt'\n",
    "    config['results_filename'] = config['trial_filename'] + '_results.csv'\n",
    "    config['aggregated_subdatasets'] = config['root_dir'] + '/' + config['subdataset']\n",
    "    full_text = open(config['aggregated_subdatasets'], 'r').read() \n",
    "    config['chars'] = sorted(list(set(full_text)))\n",
    "    print(config['chars'])\n",
    "    \n",
    "    if not os.path.exists(config['trial_dir']):\n",
    "        os.mkdir(config['trial_dir'])\n",
    "    \n",
    "    return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_samples(config, language, task):\n",
    "    \n",
    "    filename = config['root_dir'] + '/' + config['subdatasets_dir'] + '/' + language + '_' + config['subdataset']\n",
    "    if config['episodes'] == 1:\n",
    "        print('%s: processing \"%s\" data from %s' %(language, task, filename))\n",
    "    \n",
    "    wanted_samples = config['n_samples']\n",
    "    \n",
    "    df = pd.read_csv(filename)    \n",
    "    if df.shape[0] < wanted_samples:\n",
    "        print('WARNING: ', language, 'n_samples=', df.shape[0])\n",
    "        if df.shape[0] > config['n_test']:\n",
    "            wanted_samples = df.shape[0]\n",
    "        else:\n",
    "            print('ERROR: ', language, 'not enough samples')\n",
    "            return\n",
    "\n",
    "    df = df.sample(wanted_samples)\n",
    "    \n",
    "    df_train = pd.DataFrame(columns=config['features'])\n",
    "    df_test = pd.DataFrame(columns=config['features'])\n",
    "        \n",
    "    # only keep 2 columns\n",
    "    df = df[['Word', 'Pronunciation']]\n",
    "    print(df.head(5))\n",
    "    \n",
    "    n_max = df.shape[0]\n",
    "    n_test = config['n_test']\n",
    "    n_train = int(n_max - n_test)\n",
    "    \n",
    "    n = 0\n",
    "    for index, line in df.iterrows():\n",
    "        \n",
    "        word = line['Word']\n",
    "        try:\n",
    "            l_word = len(word)\n",
    "            if l_word > config['output_max_len']:\n",
    "                continue\n",
    "        except:\n",
    "            continue            \n",
    "        pron = line['Pronunciation']\n",
    "        try:\n",
    "            l_pron = len(pron)\n",
    "            if l_pron > config['output_max_len']:\n",
    "                continue\n",
    "        except:\n",
    "            continue\n",
    "        l_word = len(word)\n",
    "        l_pron = len(pron)\n",
    "        \n",
    "        if task == 'read':\n",
    "            input = word        \n",
    "            output = pron \n",
    "        elif task == 'write':\n",
    "            input = pron       \n",
    "            output = word \n",
    "        else:\n",
    "            print('ERROR: task=',task,'should not happen')\n",
    "            return\n",
    "        \n",
    "        sample = {'Language': language, 'Task':task[0], 'Input': input, 'Output': output}\n",
    "        if n < n_test:\n",
    "            df_test = df_test.append(sample, ignore_index = True)\n",
    "        else:\n",
    "            df_train = df_train.append(sample, ignore_index = True)\n",
    "        n += 1\n",
    "            \n",
    "    # append results to our train and test datasets\n",
    "    df_train.to_csv(config['train_filename'], mode='a', index=False, header=False)\n",
    "    df_test.to_csv(config['test_filename'], mode='a', index=False, header=False)\n",
    "    \n",
    "    return\n",
    "    \n",
    "def generate_datasets(config):\n",
    "    \n",
    "    # init our two datasets\n",
    "    df_train = pd.DataFrame(columns=config['features'])\n",
    "    df_test = pd.DataFrame(columns=config['features'])\n",
    "    \n",
    "    # overwrite previous files\n",
    "    df_train.to_csv(config['train_filename'], index=False, header=False)\n",
    "    df_test.to_csv(config['test_filename'], index=False, header=False)\n",
    "    \n",
    "    # fill our two datasets\n",
    "    for language in config['languages']:\n",
    "        for task in config['tasks']:\n",
    "            add_samples(config, language, task)\n",
    "\n",
    "\n",
    "def shuffle_datasets(config):\n",
    "    df_train = pd.read_csv(config['train_filename'], header=None, names=config['features'])    \n",
    "    df_train = df_train.sample(frac=1)\n",
    "    df_train.to_csv(config['train_filename'], index=False, header=False)\n",
    "    \n",
    "    df_test = pd.read_csv(config['test_filename'], header=None, names=config['features'])\n",
    "    df_test = df_test.sample(frac=1)\n",
    "    df_test.to_csv(config['test_filename'], index=False, header=False)\n",
    "    \n",
    "# minimalist check of the datasets generated\n",
    "def check_datasets(config, debug=False):\n",
    "    df_train = pd.read_csv(config['train_filename'], header=None, names=config['features'])\n",
    "    df_test = pd.read_csv(config['test_filename'], header=None, names=config['features'])\n",
    "    \n",
    "    for step in ['train', 'test']:\n",
    "        if step == 'train':\n",
    "            df = df_train\n",
    "        else:\n",
    "            df = df_test\n",
    "            \n",
    "        if debug:\n",
    "            print(step, 'shape:', df.shape)\n",
    "            print(step, 'Input min len:', df.Input.str.len().min())\n",
    "            print(step, 'Input max len:', df.Input.str.len().max())\n",
    "            print(step, 'Output min len:', df.Output.str.len().min())\n",
    "            print(step, 'Output max len:', df.Output.str.len().max())\n",
    "        \n",
    "        assert(df.Input.str.len().max() <= config['output_max_len'])\n",
    "        assert(df.Output.str.len().max() <= config['output_max_len'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_train_test_datasets(config):\n",
    "    generate_datasets(config)\n",
    "    shuffle_datasets(config)\n",
    "    check_datasets(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class CharDataset(Dataset):\n",
    "\n",
    "    def __init__(self, chars, data, block_size, debug=False):\n",
    "        #chars = sorted(list(set(data)))\n",
    "        data_size, vocab_size = len(data), len(chars)\n",
    "        if debug:\n",
    "            print('data has %d characters, %d unique.' % (data_size, vocab_size))\n",
    "        \n",
    "        self.stoi = { ch:i for i,ch in enumerate(chars) }\n",
    "        self.itos = { i:ch for i,ch in enumerate(chars) }\n",
    "        self.block_size = block_size\n",
    "        self.vocab_size = vocab_size\n",
    "        self.data = data\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data) - self.block_size\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # grab a chunk of (block_size + 1) characters from the data\n",
    "        chunk = self.data[idx:idx + self.block_size + 1]\n",
    "        # encode every character to an integer\n",
    "        idx = [self.stoi[s] for s in chunk]\n",
    "        \"\"\"\n",
    "        arrange data and targets so that the first i elements of x\n",
    "        will be asked to predict the i-th element of y. Notice that\n",
    "        the eventual language model will actually make block_size\n",
    "        individual predictions at the same time based on this data,\n",
    "        so we are being clever and amortizing the cost of the forward\n",
    "        pass of the network. So for example if block_size is 4, then\n",
    "        we could e.g. sample a chunk of text \"hello\", the integers in\n",
    "        x will correspond to \"hell\" and in y will be \"ello\". This will\n",
    "        then actually \"multitask\" 4 separate examples at the same time\n",
    "        in the language model:\n",
    "        - given just \"h\", please predict \"e\" as next\n",
    "        - given \"he\" please predict \"l\" next\n",
    "        - given \"hel\" predict \"l\" next\n",
    "        - given \"hell\" predict \"o\" next\n",
    "        \n",
    "        In addition, because the DataLoader will create batches of examples,\n",
    "        every forward/backward pass during traning will simultaneously train\n",
    "        a LOT of predictions, amortizing a lot of computation. In particular,\n",
    "        for a batched input of integers X (B, T) where B is batch size and\n",
    "        T is block_size and Y (B, T), the network will during training be\n",
    "        simultaneously training to make B*T predictions, all at once! Of course,\n",
    "        at test time we can paralellize across batch B, but unlike during training\n",
    "        we cannot parallelize across the time dimension T - we have to run\n",
    "        a forward pass of the network to recover the next single character of the \n",
    "        sequence along each batch dimension, and repeatedly always feed in a next\n",
    "        character to get the next one.\n",
    "        \n",
    "        So yes there is a big asymmetry between train/test time of autoregressive\n",
    "        models. During training we can go B*T at a time with every forward pass,\n",
    "        but during test time we can only go B at a time, T times, with T forward \n",
    "        passes.\n",
    "        \"\"\"\n",
    "        x = torch.tensor(idx[:-1], dtype=torch.long)\n",
    "        y = torch.tensor(idx[1:], dtype=torch.long)\n",
    "        return x, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_pron(config, train_dataset, trainer, model, word):\n",
    "    try:\n",
    "        x = torch.tensor([train_dataset.stoi[s] for s in word], dtype=torch.long)[None,...].to(trainer.device)\n",
    "        y = sample(model, x, config['output_max_len'], temperature=1.0, sample=True, top_k=10)[0]\n",
    "        completion = ''.join([train_dataset.itos[int(i)] for i in y])\n",
    "    except:\n",
    "        e = sys.exc_info()[0]\n",
    "        print('predict_pron(): error %s for word:%s' % (e, word))\n",
    "        # Typically, this can happen if a tested word contains a char\n",
    "        # that did not existing during the training step\n",
    "        completion = 'N/A'\n",
    "    return completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(config):\n",
    "\n",
    "    training_t0 = datetime.datetime.now()  \n",
    "    \n",
    "    block_size = config['block_size']\n",
    "    \n",
    "    print(\"config['train_filename']:\", config['train_filename'])        \n",
    "    text = open(config['train_filename'], 'r').read() \n",
    "    train_dataset = CharDataset(config['chars'], text, block_size, debug=True) \n",
    "\n",
    "    # create model\n",
    "    mconf = GPTConfig(train_dataset.vocab_size, train_dataset.block_size,\n",
    "                      n_layer=config['n_layer'], \n",
    "                      n_head=config['n_head'], \n",
    "                      n_embd=config['n_embd'])\n",
    "\n",
    "    model = GPT(mconf)\n",
    "\n",
    "    pytorch_total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    print('ANN parameters: %d' % pytorch_total_params)\n",
    "    \n",
    "    # train\n",
    "    tconf = TrainerConfig(max_epochs=2, batch_size=config['batch_size'], learning_rate=6e-4,\n",
    "                          lr_decay=True, warmup_tokens=512*20, \n",
    "                          final_tokens=2*len(train_dataset)*block_size,\n",
    "                          num_workers=4,\n",
    "                          tqdm=not config['do_finetune'])\n",
    "    trainer = Trainer(model, train_dataset, None, tconf)\n",
    "    trainer.train()\n",
    "    training_t1 = datetime.datetime.now()  \n",
    "    training_duration = training_t1 - training_t0\n",
    "    print('training_duration', training_duration)\n",
    "    \n",
    "    torch.save(model.state_dict(), config['model_filename'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(config):\n",
    "    # following two lines are copied from train()\n",
    "    block_size = config['block_size']\n",
    "    text = open(config['train_filename'], 'r').read() \n",
    "    train_dataset = CharDataset(config['chars'], text, config['block_size']) \n",
    "                       \n",
    "    mconf = GPTConfig(train_dataset.vocab_size, train_dataset.block_size,                       \n",
    "                      n_layer=config['n_layer'], \n",
    "                      n_head=config['n_head'], \n",
    "                      n_embd=config['n_embd'])\n",
    "    model = GPT(mconf)\n",
    "    model.load_state_dict(torch.load(config['model_filename']))\n",
    "    model.eval()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(config, task, language, df_results):\n",
    "    \n",
    "    model = get_model(config)\n",
    "    \n",
    "    # the following two lines are copied from train()\n",
    "    block_size = config['block_size']\n",
    "    text = open(config['train_filename'], 'r').read() \n",
    "    train_dataset = CharDataset(config['chars'], text, block_size) \n",
    "\n",
    "    \n",
    "    tconf = TrainerConfig(max_epochs=2, batch_size=config['batch_size'], learning_rate=6e-4,\n",
    "                          lr_decay=True, warmup_tokens=512*20, \n",
    "                          final_tokens=2*len(train_dataset)*block_size,\n",
    "                          num_workers=4)\n",
    "    trainer = Trainer(model, train_dataset, None, tconf)\n",
    "    \n",
    "    # test\n",
    "    testing_t0 = datetime.datetime.now() \n",
    "    \n",
    "    df_test = pd.read_csv(config['test_filename'], header=None, names=config['features'])    \n",
    "\n",
    "    n = 0\n",
    "    n_ok = 0\n",
    "    n_ko = 0\n",
    "    for index, row in df_test.iterrows():\n",
    "        \n",
    "        if row.Task != task[0] or row.Language != language:\n",
    "            continue\n",
    "        \n",
    "        n += 1\n",
    "        \n",
    "        # build the context \n",
    "        context = language + ',' + task[0] + ',' + row.Input + ','\n",
    "        \n",
    "        # get the predicted output string\n",
    "        prediction_padded = predict_pron(config, train_dataset, trainer, model, context)\n",
    "        \n",
    "        # identify where the interesting output is in the raw output\n",
    "        if prediction_padded.startswith(context):\n",
    "            \n",
    "            # remove unwanted prefix\n",
    "            prediction_padded = prediction_padded[len(context):]     \n",
    "            \n",
    "            # remove unwanted postfix (i.e. remove padding)\n",
    "            eos = prediction_padded.find('\\n', 1)\n",
    "            if eos < 0:\n",
    "                n_ko += 1\n",
    "            else:\n",
    "                #prediction = prediction_padded[:eos_p]\n",
    "                #target = row.Output[:eos_t]\n",
    "                prediction = prediction_padded[:eos]\n",
    "                target = row.Output\n",
    "                # check if prediction is same as target\n",
    "                if prediction == target:\n",
    "                    n_ok += 1\n",
    "                    #if config['print_predictions_ok'] and language != 'eno':\n",
    "                    if config['print_predictions_ok'] and language == 'zh':\n",
    "                        print('input: %s,%s,%s => prediction:%s ok (target:%s)' \n",
    "                              % (language, task, row.Input, prediction, target))                    \n",
    "                else:\n",
    "                    n_ko += 1\n",
    "                    if config['print_predictions_ko'] and language != 'eno':\n",
    "                        print('input: %s,%s,%s => prediction:%s KO! (target:%s)' \n",
    "                              % (language, task, row.Input, prediction, target))                    \n",
    "        else:\n",
    "            n_ko += 1\n",
    "\n",
    "    pctg_ok = int(n_ok/n*100)\n",
    "    pctg_ko = 100 - pctg_ok\n",
    "    if config['episodes'] == 1 or config['print_test_results'] == 1:\n",
    "        print('%s %5s: n=%d, n_ok=%d, n_ko=%d => %%n_ok=%d%%' % (language, task, n, n_ok, n_ko, pctg_ok))\n",
    "    testing_t1 = datetime.datetime.now()  \n",
    "    test_duration = testing_t1 - testing_t0\n",
    "    \n",
    "    dict_res = {'lang': language, 'task':task, 'test_accuracy': n_ok/n, \n",
    "                #'training_duration': training_duration, \n",
    "                'test_duration': test_duration}\n",
    "    return dict_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_tests(config):\n",
    "    \n",
    "    # open the file for being able to append the results of this test\n",
    "    # otherwise create a new one\n",
    "    df_results = pd.DataFrame()\n",
    "\n",
    "    for episode in range(config['episodes']):\n",
    "        print('episode:', episode)\n",
    "             \n",
    "        init_train_test_datasets(config)\n",
    "        \n",
    "        # train the ANN for all available languages in the training dataset\n",
    "        # i.e. multi-language training\n",
    "        train(config)\n",
    "        \n",
    "        # test the ANN for each languages\n",
    "        for language in config['languages']:\n",
    "            for task in config['tasks']:\n",
    "                dict_res = test(config, task, language, df_results)\n",
    "                # put the results as a new line in the CSV history file\n",
    "                df_res = pd.DataFrame(data = [dict_res.values()], columns = dict_res.keys())\n",
    "                df_results = pd.concat([df_results, df_res], axis=0, ignore_index=True, sort=False)\n",
    "                df_results.to_csv(config['results_filename'], index=None, header=True)\n",
    "                \n",
    "    acc = df_results.test_accuracy.mean()\n",
    "    print('accuracy:%.2f' % acc)\n",
    "    \n",
    "    return df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tests(config):\n",
    "\n",
    "    # open the file for being able to append the results of this test\n",
    "    # otherwise create a new one\n",
    "    df_results = pd.DataFrame()\n",
    "\n",
    "    for episode in range(config['episodes']):\n",
    "        print('episode:', episode)\n",
    "        \n",
    "        # test the ANN for each languages\n",
    "        for language in config['languages']:\n",
    "            for task in config['tasks']:\n",
    "                dict_res = test(config, task, language, df_results)\n",
    "                # put the results as a new line in the CSV history file\n",
    "                df_res = pd.DataFrame(data = [dict_res.values()], columns = dict_res.keys())\n",
    "                df_results = pd.concat([df_results, df_res], axis=0, ignore_index=True, sort=False)\n",
    "                df_results.to_csv(config['results_filename'], index=None, header=True)\n",
    "    \n",
    "    acc = df_results.test_accuracy.mean()\n",
    "    print('accuracy:%.2f' % acc)\n",
    "    \n",
    "    return df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import ray\n",
    "import ray.tune as tune\n",
    "\n",
    "def get_6_digits():\n",
    "    str_digits =  ''\n",
    "    for i in range(6):\n",
    "        digit = random.randint(0,9)\n",
    "        str_digits += str(digit)\n",
    "    return(str_digits)\n",
    "        \n",
    "def ray_train_and_tests(config):\n",
    "        \n",
    "        # update config with two additional parameters related to phonemes\n",
    "        config = extend_config(config) \n",
    "        config['ray_tune'] = True\n",
    "        \n",
    "        ray_instance = 'ray_test_'+ get_6_digits()        \n",
    "        #config['trial_dir'] = os.getcwd()\n",
    "        #+ '/' + config['root_label'] + '_' + ray_instance\n",
    "        print(config)\n",
    "        \n",
    "        df_results = train_and_tests(config)\n",
    "        acc = df_results.test_accuracy.mean()\n",
    "        tune.report(accuracy=acc)\n",
    "        \n",
    "        \n",
    "def finetune_hyperparameters():\n",
    "\n",
    "    FINETUNING_CONFIG = {            \n",
    "        'episodes': tune.grid_search([3]),\n",
    "        'n_train': tune.grid_search([10000]),\n",
    "        'n_layer': tune.grid_search([2, 4]),\n",
    "        'n_head': tune.grid_search([4]), \n",
    "        'n_embd': tune.grid_search([336]),\n",
    "        'batch_size': tune.grid_search([128, 256]),        \n",
    "    }\n",
    "    \n",
    "    test_name = 'ray_test_' + get_6_digits()\n",
    "    print('test_name:%s' % test_name)\n",
    "\n",
    "    # https://docs.ray.io/en/latest/tune/api_docs/execution.html?highlight=tune%20run\n",
    "    analysis = tune.run(\n",
    "        ray_train_and_tests, \n",
    "        config=FINETUNING_CONFIG, \n",
    "        resources_per_trial={'gpu': 4},\n",
    "        name=test_name,\n",
    "        local_dir= os.getcwd() + '/' + 'ray_results',\n",
    "        metric=\"accuracy\", \n",
    "        mode=\"max\"\n",
    "        )\n",
    "\n",
    "    print(\"Best config: \", analysis.get_best_config())\n",
    "\n",
    "    # Get a dataframe for analyzing trial results.\n",
    "    df_ray = analysis.dataframe()\n",
    "\n",
    "    return df_ray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    config = extend_config(CONFIG)\n",
    "    if config['do_finetune']:\n",
    "        ray.init()\n",
    "        df_results = finetune_hyperparameters()\n",
    "    else:\n",
    "        if config['do_train']:\n",
    "            df_results = train_and_tests(config)\n",
    "        else:\n",
    "            df_results = tests(config)\n",
    "    return df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\n', \"'\", ',', '0', '1', ':', 'B', 'P', 'R', 'T', 'V', 'W', '_', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', 'ß', 'à', 'á', 'â', 'ã', 'ä', 'æ', 'ç', 'è', 'é', 'ê', 'ë', 'ì', 'í', 'î', 'ï', 'ð', 'ñ', 'ò', 'ó', 'ô', 'õ', 'ö', 'ø', 'ù', 'ú', 'û', 'ü', 'ć', 'ĉ', 'č', 'đ', 'ĝ', 'ğ', 'ĥ', 'ħ', 'ĩ', 'ı', 'ĵ', 'ŋ', 'œ', 'ŝ', 'ş', 'š', 'ũ', 'ŭ', 'ž', 'ɐ', 'ɑ', 'ɒ', 'ɔ', 'ɕ', 'ə', 'ɚ', 'ɛ', 'ɟ', 'ɡ', 'ɣ', 'ɤ', 'ɥ', 'ɦ', 'ɨ', 'ɪ', 'ɫ', 'ɭ', 'ɯ', 'ɰ', 'ɱ', 'ɲ', 'ɵ', 'ɸ', 'ɹ', 'ɾ', 'ɿ', 'ʁ', 'ʂ', 'ʃ', 'ʅ', 'ʊ', 'ʋ', 'ʌ', 'ʍ', 'ʎ', 'ʏ', 'ʐ', 'ʑ', 'ʒ', 'ʔ', 'ʕ', 'ʝ', 'ʣ', 'ʤ', 'ʦ', 'ʧ', 'ʰ', 'ʷ', 'ː', 'ˤ', '˥', '˦', '˧', '˨', '˩', '̃', '̚', '̹', '͈', 'β', 'θ', 'χ', 'а', 'б', 'в', 'г', 'д', 'е', 'ж', 'з', 'и', 'й', 'к', 'л', 'м', 'н', 'о', 'п', 'р', 'с', 'т', 'у', 'ф', 'х', 'ц', 'ч', 'ш', 'щ', 'ъ', 'ы', 'ь', 'э', 'ю', 'я', 'ё', 'ء', 'آ', 'أ', 'ؤ', 'إ', 'ئ', 'ا', 'ب', 'ة', 'ت', 'ث', 'ج', 'ح', 'خ', 'د', 'ذ', 'ر', 'ز', 'س', 'ش', 'ص', 'ض', 'ط', 'ظ', 'ع', 'غ', 'ف', 'ق', 'ك', 'ل', 'م', 'ن', 'ه', 'و', 'ى', 'ي', 'ً', 'ٌ', 'ٍ', 'َ', 'ُ', 'ِ', 'ّ', 'ْ', 'ٓ', 'ٰ', 'ی', 'ᄀ', 'ᄁ', 'ᄂ', 'ᄃ', 'ᄄ', 'ᄅ', 'ᄆ', 'ᄇ', 'ᄈ', 'ᄉ', 'ᄊ', 'ᄋ', 'ᄌ', 'ᄍ', 'ᄎ', 'ᄏ', 'ᄐ', 'ᄑ', 'ᄒ', 'ᅡ', 'ᅢ', 'ᅣ', 'ᅤ', 'ᅥ', 'ᅦ', 'ᅧ', 'ᅨ', 'ᅩ', 'ᅪ', 'ᅫ', 'ᅬ', 'ᅭ', 'ᅮ', 'ᅯ', 'ᅰ', 'ᅱ', 'ᅲ', 'ᅳ', 'ᅴ', 'ᅵ', 'ᆨ', 'ᆩ', 'ᆪ', 'ᆫ', 'ᆬ', 'ᆭ', 'ᆮ', 'ᆯ', 'ᆰ', 'ᆱ', 'ᆲ', 'ᆳ', 'ᆴ', 'ᆵ', 'ᆶ', 'ᆷ', 'ᆸ', 'ᆹ', 'ᆺ', 'ᆻ', 'ᆼ', 'ᆽ', 'ᆾ', 'ᆿ', 'ᇀ', 'ᇁ', 'ᇂ', 'ẽ', 'ỹ', '㑩', '㝉', '㧑', '㨫', '䁖', '䌹', '䌽', '䗖', '䜣', '䜩', '䝙', '䲠', '䴘', '䴙', '一', '丁', '七', '万', '丈', '三', '上', '下', '不', '与', '丐', '丑', '专', '且', '世', '丘', '丙', '业', '丛', '东', '丝', '丢', '两', '严', '丧', '个', '丫', '中', '丰', '串', '临', '丸', '丹', '为', '主', '丽', '举', '乃', '久', '么', '义', '之', '乌', '乎', '乏', '乐', '乔', '乖', '乘', '乙', '九', '乞', '也', '习', '乡', '书', '买', '乱', '乳', '乾', '了', '予', '争', '事', '二', '于', '亏', '云', '互', '五', '井', '亘', '亚', '些', '亡', '亢', '交', '亥', '亦', '产', '亩', '享', '京', '亭', '亮', '亲', '亵', '亸', '人', '亿', '什', '仁', '仂', '仄', '仅', '仆', '仇', '今', '介', '仍', '从', '仑', '仓', '仔', '他', '仗', '付', '仙', '代', '令', '以', '仪', '们', '仰', '件', '价', '任', '份', '仿', '企', '伉', '伍', '伎', '伏', '伐', '休', '众', '优', '伙', '会', '伛', '伞', '伟', '传', '伤', '伥', '伦', '伧', '伪', '伫', '伯', '估', '伴', '伶', '伸', '伺', '似', '佃', '但', '位', '低', '住', '佐', '佑', '体', '何', '余', '佛', '作', '佝', '佞', '你', '佣', '佥', '佩', '佬', '佯', '佳', '佻', '使', '侃', '侄', '侈', '例', '供', '依', '侠', '侣', '侥', '侦', '侧', '侨', '侩', '侪', '侮', '侵', '便', '促', '俄', '俊', '俏', '俗', '俘', '俚', '保', '俟', '信', '俣', '俦', '俨', '俩', '俪', '俭', '修', '俯', '俸', '倍', '倏', '倒', '倔', '候', '倚', '倜', '借', '倡', '倥', '倦', '倩', '债', '值', '倾', '假', '偏', '做', '停', '健', '偬', '偶', '偷', '偻', '偾', '偿', '傅', '傍', '傥', '傧', '储', '傩', '催', '傲', '傻', '像', '僚', '僧', '僮', '僵', '僻', '儿', '兀', '允', '元', '兄', '充', '兆', '先', '光', '克', '免', '兑', '兔', '党', '兜', '兢', '入', '全', '八', '公', '六', '兰', '共', '关', '兴', '兵', '其', '具', '典', '兹', '养', '兼', '兽', '冁', '内', '冈', '冉', '册', '再', '冏', '冒', '冕', '冗', '写', '军', '农', '冠', '冢', '冤', '冥', '冬', '冯', '冰', '冲', '决', '况', '冶', '冷', '冻', '冽', '净', '凄', '准', '凉', '凋', '凌', '减', '凑', '凛', '凝', '几', '凡', '凤', '凫', '凭', '凯', '凰', '凳', '凶', '凸', '凹', '出', '击', '凼', '函', '凿', '刀', '刁', '刃', '分', '切', '刊', '刍', '刑', '划', '列', '刘', '则', '刚', '创', '初', '删', '判', '刨', '利', '别', '刬', '刭', '刮', '到', '制', '刷', '券', '刹', '刺', '刻', '刽', '刿', '剀', '剂', '剃', '削', '前', '剐', '剑', '剖', '剥', '剧', '剩', '剪', '副', '割', '剽', '剿', '劈', '力', '劝', '办', '功', '加', '务', '劢', '劣', '动', '助', '劫', '励', '劲', '劳', '劾', '势', '勃', '勇', '勉', '勋', '勒', '勘', '募', '勤', '勺', '勾', '匀', '包', '匆', '化', '北', '匙', '匝', '匠', '匣', '匦', '匪', '匮', '匹', '区', '医', '匾', '匿', '十', '千', '升', '午', '半', '华', '协', '卑', '卒', '卓', '单', '卖', '南', '博', '卜', '占', '卡', '卢', '卤', '卦', '卧', '卫', '卮', '卯', '印', '危', '即', '却', '卵', '卷', '卸', '卺', '厂', '厄', '厅', '历', '厉', '压', '厌', '厐', '厕', '厘', '厚', '原', '厢', '厥', '厦', '厨', '厩', '厮', '去', '厾', '县', '叁', '参', '叆', '叇', '又', '叉', '及', '友', '双', '反', '发', '取', '受', '变', '叙', '叛', '叠', '口', '古', '句', '另', '叨', '叩', '只', '叫', '召', '叮', '可', '台', '叱', '史', '右', '叶', '号', '司', '叹', '叽', '吁', '吃', '各', '合', '吊', '同', '名', '后', '吏', '吐', '向', '吓', '吕', '吗', '君', '吝', '吞', '吟', '吣', '否', '吧', '吨', '含', '听', '吭', '启', '吱', '吵', '吸', '吹', '吻', '吼', '呆', '呈', '告', '呐', '呒', '呓', '呕', '呖', '呗', '员', '呛', '呜', '呢', '周', '呫', '味', '呵', '呼', '命', '和', '咎', '咏', '咐', '咒', '咕', '咙', '咛', '咝', '咣', '咨', '咩', '咪', '咬', '咱', '咳', '咸', '咽', '咿', '哀', '品', '哂', '哄', '哈', '响', '哑', '哒', '哓', '哔', '哕', '哗', '哙', '哜', '哝', '哥', '哪', '哭', '哮', '哲', '哺', '哼', '唁', '唆', '唇', '唏', '唐', '唛', '唠', '唢', '唣', '唤', '唬', '售', '唯', '唱', '唾', '啀', '啃', '啄', '商', '啓', '啕', '啖', '啜', '啡', '啥', '啦', '啧', '啪', '啬', '啭', '啮', '啯', '啰', '啴', '啷', '啸', '啼', '喀', '喂', '善', '喉', '喊', '喋', '喑', '喘', '喜', '喝', '喧', '喷', '喻', '喽', '喾', '嗅', '嗉', '嗑', '嗓', '嗔', '嗜', '嗣', '嗥', '嗦', '嗫', '嗳', '嘈', '嘉', '嘎', '嘘', '嘛', '嘟', '嘤', '嘱', '嘲', '嘴', '嘶', '嘻', '噍', '噏', '噜', '器', '噩', '噪', '嚅', '嚎', '嚏', '嚣', '嚼', '囊', '囚', '四', '回', '囟', '因', '团', '囤', '囫', '园', '困', '囱', '围', '囵', '固', '国', '图', '圃', '圆', '圈', '圉', '圜', '土', '圣', '在', '圮', '地', '圹', '场', '址', '坂', '均', '坊', '坎', '坏', '坐', '坑', '块', '坚', '坛', '坜', '坝', '坞', '坟', '坠', '坡', '坤', '坦', '坨', '坩', '坳', '垂', '垄', '垅', '垆', '型', '垒', '垛', '垠', '垢', '垣', '垦', '垩', '垫', '垭', '垮', '垲', '垴', '埃', '埋', '城', '埘', '埙', '埚', '域', '埠', '培', '基', '堂', '堆', '堑', '堕', '堙', '堡', '堤', '堪', '堰', '堵', '塌', '塍', '塑', '塔', '塞', '填', '境', '墓', '墙', '增', '墟', '墨', '墩', '壁', '壑', '壕', '士', '壮', '声', '壳', '壶', '壸', '处', '备', '复', '夕', '外', '夙', '多', '夜', '够', '夤', '夥', '大', '天', '太', '夫', '央', '夯', '失', '头', '夷', '夸', '夹', '夺', '奁', '奂', '奇', '奈', '奉', '奋', '奎', '奏', '契', '奔', '奖', '套', '奠', '奢', '奥', '女', '奴', '奶', '奸', '她', '好', '如', '妃', '妄', '妆', '妇', '妈', '妊', '妍', '妒', '妓', '妖', '妙', '妥', '妨', '妩', '妪', '妹', '妻', '妾', '姆', '姊', '始', '姐', '姑', '姓', '委', '姗', '姘', '姜', '姥', '姨', '姹', '姻', '姿', '威', '娃', '娄', '娅', '娆', '娇', '娈', '娘', '娜', '娟', '娱', '娴', '娶', '娼', '婀', '婆', '婉', '婚', '婢', '婪', '婴', '婵', '婶', '婿', '媒', '媚', '媛', '媪', '媳', '嫁', '嫌', '嫒', '嫔', '嫖', '嫠', '嫡', '嫩', '嫱', '嬉', '嬗', '嬷', '孀', '子', '孑', '孔', '孕', '字', '存', '孙', '孝', '季', '孤', '学', '孩', '孪', '孬', '孱', '孽', '宁', '它', '宅', '宇', '守', '安', '完', '宏', '宗', '官', '定', '宜', '宝', '实', '宠', '审', '客', '宣', '室', '宥', '宦', '宪', '宫', '宰', '害', '宴', '宵', '家', '容', '宽', '宾', '宿', '寂', '寄', '寅', '密', '寇', '富', '寐', '寒', '寓', '寝', '察', '寡', '寨', '寸', '对', '寺', '寻', '导', '寿', '封', '射', '将', '尊', '小', '少', '尔', '尖', '尘', '尚', '尜', '尝', '尤', '尬', '就', '尴', '尸', '尺', '尼', '尽', '尾', '尿', '局', '屁', '层', '屃', '屄', '居', '屈', '屉', '届', '屋', '屎', '屏', '屑', '展', '属', '屠', '屡', '履', '屦', '屯', '山', '屿', '岁', '岂', '岐', '岔', '岖', '岗', '岚', '岛', '岩', '岭', '岳', '岸', '岿', '峒', '峙', '峡', '峤', '峥', '峦', '峨', '峭', '峰', '峻', '崎', '崖', '崩', '崭', '崽', '嵌', '嵘', '嵚', '嵝', '嵩', '嵴', '巅', '巆', '巍', '川', '巡', '巢', '工', '左', '巧', '巨', '巩', '巫', '差', '己', '已', '巳', '巴', '巾', '币', '市', '布', '帅', '帆', '师', '希', '帏', '帐', '帖', '帘', '帚', '帛', '帜', '帝', '带', '帧', '席', '帮', '帱', '帷', '常', '帻', '帼', '帽', '幂', '幅', '幔', '幕', '干', '平', '年', '并', '幸', '幺', '幻', '幼', '幽', '广', '庄', '庆', '庇', '床', '序', '庐', '庑', '库', '应', '底', '庖', '店', '庙', '府', '庞', '废', '度', '座', '庭', '庵', '庶', '康', '庸', '廉', '廊', '廓', '廥', '廪', '延', '廷', '建', '开', '异', '弃', '弄', '弈', '弊', '弋', '式', '弑', '弓', '引', '弘', '弛', '弟', '张', '弥', '弦', '弧', '弩', '弪', '弯', '弱', '弹', '强', '弼', '归', '当', '录', '彖', '彝', '形', '彦', '彩', '彪', '彰', '影', '役', '彻', '往', '征', '径', '待', '徇', '律', '徐', '徒', '徕', '得', '徙', '御', '循', '微', '徯', '德', '徼', '徽', '心', '必', '忆', '忌', '忍', '忏', '志', '忘', '忙', '忠', '忤', '忧', '快', '忱', '念', '忽', '忾', '忿', '怀', '态', '怂', '怃', '怄', '怅', '怆', '怎', '怒', '怔', '怕', '怖', '怛', '怜', '思', '怠', '怡', '急', '性', '怨', '怪', '怯', '怵', '总', '怼', '怿', '恁', '恃', '恋', '恍', '恐', '恒', '恕', '恙', '恢', '恤', '恨', '恩', '恪', '恫', '恬', '恭', '息', '恰', '恳', '恶', '恸', '恹', '恺', '恻', '恼', '恿', '悄', '悉', '悌', '悍', '悒', '悔', '悖', '悚', '悟', '悠', '患', '悦', '悫', '悬', '悭', '悯', '悲', '悴', '悸', '悼', '情', '惆', '惊', '惋', '惑', '惘', '惙', '惜', '惟', '惠', '惦', '惧', '惨', '惩', '惫', '惬', '惭', '惮', '惯', '惰', '想', '惶', '惹', '惺', '愁', '愆', '愈', '愉', '愎', '意', '愕', '愚', '感', '愠', '愣', '愤', '愦', '愧', '愿', '慈', '慌', '慎', '慑', '慕', '慢', '慧', '慨', '慰', '慵', '憋', '憎', '憔', '憨', '憩', '憷', '憾', '懂', '懈', '懊', '懑', '懒', '懔', '懮', '懿', '戆', '戈', '戋', '戌', '戍', '戎', '戏', '成', '我', '戒', '或', '戗', '战', '戚', '戛', '截', '戬', '戮', '戳', '戴', '户', '戾', '房', '所', '扁', '扇', '扉', '手', '才', '扎', '扑', '扒', '打', '扔', '托', '扛', '扣', '执', '扩', '扪', '扫', '扬', '扭', '扮', '扯', '扰', '扳', '扶', '批', '扼', '找', '承', '技', '抃', '抄', '抉', '把', '抏', '抑', '抒', '抓', '投', '抖', '抗', '折', '抚', '抛', '抟', '抠', '抡', '抢', '护', '报', '抨', '披', '抬', '抱', '抵', '抹', '抻', '押', '抽', '拂', '担', '拆', '拇', '拉', '拌', '拍', '拐', '拒', '拓', '拔', '拖', '拗', '拘', '拙', '拚', '招', '拜', '拟', '拢', '拣', '拥', '拦', '拧', '拨', '择', '括', '拮', '拱', '拳', '拷', '拼', '拾', '拿', '持', '挂', '指', '挈', '按', '挑', '挖', '挚', '挛', '挝', '挞', '挟', '挠', '挡', '挢', '挣', '挤', '挥', '挦', '挨', '挪', '挫', '振', '挲', '挹', '挺', '挽', '捂', '捆', '捉', '捍', '捎', '捏', '捐', '捕', '捞', '损', '捡', '换', '捣', '捧', '捩', '据', '捱', '捶', '捷', '掀', '掇', '授', '掉', '掌', '掏', '掐', '排', '掖', '掘', '掠', '探', '掣', '接', '控', '推', '掩', '措', '掬', '掰', '掳', '掴', '掷', '掺', '掼', '揄', '揆', '描', '提', '插', '揖', '揘', '握', '揣', '揪', '揭', '援', '揽', '揾', '揿', '搀', '搁', '搂', '搅', '搋', '搏', '搔', '搜', '搞', '搬', '搭', '携', '摄', '摅', '摆', '摇', '摈', '摊', '摒', '摔', '摘', '摞', '摧', '摩', '摸', '摹', '摺', '撄', '撅', '撇', '撑', '撒', '撕', '撞', '撤', '撩', '撬', '播', '撰', '撵', '撷', '撸', '撺', '撼', '擂', '擅', '操', '擒', '擘', '擞', '擦', '攀', '攒', '攘', '攥', '攫', '支', '收', '攸', '改', '攻', '放', '政', '故', '效', '敌', '敏', '救', '敕', '敖', '教', '敚', '敛', '敞', '敢', '散', '敦', '敬', '数', '敲', '敳', '整', '敷', '文', '斋', '斑', '斓', '斗', '料', '斜', '斤', '斥', '斧', '斩', '斫', '断', '新', '方', '施', '旁', '旅', '旋', '族', '旗', '无', '日', '旧', '旨', '早', '旬', '旱', '时', '旷', '旸', '旺', '昂', '昆', '明', '昏', '易', '昙', '星', '映', '春', '昧', '昨', '是', '昵', '昼', '昽', '显', '晃', '晋', '晒', '晓', '晔', '晕', '晖', '晚', '晤', '晦', '晨', '普', '景', '晰', '晴', '晶', '智', '晾', '暂', '暄', '暇', '暑', '暖', '暗', '暧', '暮', '暴', '曝', '曰', '曲', '曳', '更', '曹', '曾', '替', '最', '月', '有', '朋', '服', '朔', '朗', '望', '朝', '期', '朦', '木', '未', '末', '本', '札', '术', '朱', '朴', '朵', '机', '朽', '杀', '杂', '权', '杆', '杈', '杉', '杌', '李', '杏', '材', '村', '杓', '杖', '杜', '束', '杠', '条', '来', '杨', '杩', '杯', '杰', '杳', '杼', '松', '板', '极', '构', '枉', '析', '枕', '林', '枘', '枚', '果', '枝', '枞', '枢', '枣', '枥', '枧', '枨', '枪', '枫', '枭', '枯', '架', '枷', '柄', '柏', '某', '染', '柔', '柘', '柜', '柠', '查', '柩', '柬', '柱', '柳', '柴', '柽', '柿', '栅', '标', '栈', '栉', '栊', '栋', '栌', '栎', '栏', '树', '栓', '栖', '栗', '校', '株', '栲', '样', '核', '根', '格', '栽', '桁', '桂', '桃', '框', '案', '桉', '桌', '桑', '桓', '桠', '桡', '桢', '档', '桤', '桥', '桦', '桨', '桩', '桫', '桶', '梁', '梅', '梆', '梗', '梢', '梦', '梨', '梭', '梯', '械', '梳', '梼', '梿', '检', '棂', '棉', '棋', '棍', '棒', '棕', '棘', '棚', '森', '棰', '棱', '棵', '棹', '棺', '椁', '椅', '植', '椎', '椟', '椠', '椤', '椭', '椮', '椰', '楚', '楠', '楣', '楦', '楫', '楮', '楼', '概', '榄', '榆', '榈', '榉', '榔', '榕', '榛', '榜', '榨', '榫', '榴', '榻', '槁', '槛', '槟', '槭', '槽', '模', '横', '樯', '樱', '樽', '橐', '橘', '橙', '橛', '橡', '橥', '橱', '橹', '橼', '檄', '檐', '檩', '檬', '欠', '次', '欢', '欣', '欤', '欧', '欲', '欺', '款', '歇', '歌', '止', '正', '此', '步', '武', '歧', '歪', '死', '歼', '殁', '殃', '殆', '殇', '殉', '殊', '残', '殍', '殒', '殓', '殖', '殚', '殡', '殴', '段', '殷', '殿', '毁', '毂', '毅', '毋', '母', '每', '毒', '比', '毕', '毗', '毙', '毛', '毡', '毫', '毯', '毵', '氏', '民', '气', '氛', '氢', '氤', '氧', '氨', '氩', '氮', '氯', '氲', '水', '永', '氽', '汀', '汁', '求', '汇', '汉', '汗', '汛', '汞', '江', '池', '污', '汤', '汰', '汹', '汽', '沃', '沈', '沉', '沓', '沙', '沛', '沟', '没', '沤', '沥', '沦', '沧', '沫', '沮', '河', '沸', '油', '治', '沼', '沾', '沿', '泄', '泅', '泉', '泊', '泓', '法', '泛', '泞', '泡', '波', '泣', '泥', '注', '泪', '泯', '泳', '泵', '泷', '泺', '泻', '泼', '泽', '洁', '洇', '洋', '洒', '洗', '洞', '津', '洪', '洲', '活', '洼', '洽', '派', '流', '浃', '浅', '浆', '浇', '浊', '测', '浍', '济', '浏', '浑', '浒', '浓', '浔', '浚', '浣', '浦', '浩', '浪', '浮', '浴', '海', '浸', '涂', '涅', '消', '涉', '涌', '涎', '涛', '涝', '涞', '涟', '涠', '涡', '涣', '涤', '润', '涧', '涨', '涩', '涮', '涯', '液', '涵', '涸', '淀', '淅', '淆', '淋', '淌', '淑', '淘', '淡', '淤', '淫', '深', '淳', '混', '淹', '添', '清', '渊', '渌', '渍', '渎', '渐', '渔', '渗', '渠', '渡', '渣', '渥', '温', '港', '渴', '游', '渺', '湔', '湖', '湛', '湮', '湾', '湿', '溃', '溅', '溆', '溉', '源', '溜', '溟', '溢', '溪', '溯', '溶', '溷', '溺', '滋', '滑', '滗', '滚', '滞', '滟', '滠', '满', '滢', '滤', '滥', '滨', '滩', '滴', '漂', '漆', '漏', '漓', '演', '漠', '漩', '漪', '漫', '漱', '漾', '潆', '潇', '潋', '潍', '潜', '潢', '潭', '潮', '潴', '澄', '澜', '澡', '澹', '激', '濑', '濒', '濡', '灌', '灏', '火', '灭', '灯', '灰', '灵', '灶', '灸', '灼', '灾', '灿', '炀', '炉', '炊', '炎', '炒', '炕', '炖', '炜', '炝', '炭', '炮', '炯', '炳', '炸', '点', '炼', '炽', '烁', '烂', '烃', '烈', '烘', '烙', '烛', '烟', '烤', '烦', '烧', '烨', '烩', '烫', '烬', '热', '烯', '烷', '烹', '烽', '焉', '焊', '焓', '焕', '焖', '焘', '焙', '焚', '焦', '焰', '然', '煅', '煌', '煎', '煞', '煤', '煦', '照', '煮', '煽', '熄', '熊', '熏', '熔', '熙', '熟', '熠', '熨', '熬', '熳', '熵', '燃', '燕', '燥', '燮', '爆', '爪', '爬', '爱', '爵', '父', '爷', '爸', '爹', '爽', '片', '版', '牌', '牍', '牒', '牖', '牙', '牛', '牡', '牢', '牧', '物', '牴', '牵', '牸', '特', '牺', '犀', '犁', '犊', '犒', '犟', '犬', '犯', '状', '犷', '犸', '犹', '狂', '狈', '狗', '狙', '狝', '狞', '狠', '狡', '狩', '独', '狭', '狮', '狯', '狰', '狱', '狲', '狸', '狼', '猃', '猊', '猎', '猕', '猖', '猛', '猜', '猝', '猡', '猢', '猥', '猩', '猪', '猫', '猬', '献', '猳', '猴', '猿', '獐', '獭', '獾', '玄', '率', '玉', '王', '玑', '玙', '玛', '玩', '玮', '环', '现', '玲', '玳', '玺', '珊', '珍', '珏', '珐', '珑', '珞', '珠', '班', '珲', '球', '琅', '理', '琉', '琏', '琐', '琳', '琴', '琼', '瑕', '瑙', '瑛', '瑞', '瑟', '瑰', '瑶', '瑷', '璀', '璃', '璎', '璜', '璧', '瓒', '瓜', '瓢', '瓣', '瓤', '瓦', '瓮', '瓯', '瓶', '瓷', '甄', '甍', '甘', '甚', '甜', '生', '用', '甩', '田', '由', '甲', '申', '电', '男', '画', '畅', '畋', '界', '畏', '畔', '留', '畜', '略', '番', '畲', '畴', '畸', '疆', '疏', '疑', '疖', '疗', '疚', '疟', '疠', '疡', '疣', '疤', '疥', '疫', '疬', '疭', '疮', '疯', '疱', '疲', '疴', '疵', '疸', '疹', '疼', '疾', '痂', '病', '症', '痈', '痉', '痊', '痍', '痒', '痔', '痕', '痖', '痘', '痛', '痢', '痤', '痨', '痪', '痫', '痱', '痲', '痴', '痹', '痼', '痿', '瘀', '瘅', '瘆', '瘗', '瘘', '瘙', '瘠', '瘤', '瘦', '瘪', '瘫', '瘴', '瘾', '瘿', '癌', '癖', '癞', '癣', '癫', '登', '白', '百', '皂', '的', '皆', '皇', '皋', '皌', '皎', '皑', '皓', '皮', '皱', '皲', '盂', '盆', '盈', '益', '盍', '盏', '盐', '监', '盒', '盔', '盖', '盗', '盘', '盛', '盟', '目', '盯', '盲', '直', '相', '盼', '盾', '省', '眄', '眉', '看', '眍', '真', '眠', '眦', '眩', '眬', '眯', '眷', '眸', '眺', '眼', '着', '睁', '睐', '睑', '睚', '睛', '睡', '督', '睦', '睨', '睬', '睹', '睽', '睾', '睿', '瞄', '瞅', '瞈', '瞎', '瞒', '瞥', '瞧', '瞩', '瞬', '瞰', '瞻', '矍', '矛', '矜', '矢', '知', '矩', '矫', '短', '矮', '石', '矶', '矾', '矿', '砀', '码', '砂', '砌', '砍', '研', '砖', '砚', '砜', '砝', '砢', '砧', '砭', '破', '砷', '砸', '砺', '砻', '砾', '础', '硅', '硕', '硖', '硗', '硙', '硝', '硫', '硬', '确', '硷', '碇', '碌', '碍', '碎', '碑', '碗', '碛', '碜', '碟', '碧', '碰', '碱', '碳', '碾', '磁', '磅', '磕', '磨', '磬', '磷', '礁', '礮', '礴', '示', '礼', '社', '祀', '祃', '祈', '祉', '祎', '祓', '祖', '祝', '神', '祠', '祢', '祥', '祦', '票', '祭', '祯', '祷', '祸', '禀', '禁', '禄', '禅', '福', '离', '禽', '禾', '秀', '私', '秃', '秆', '秉', '秋', '种', '科', '秒', '秕', '秘', '租', '秣', '秤', '秩', '积', '称', '秸', '移', '秽', '秾', '稀', '稃', '程', '稍', '税', '稗', '稚', '稠', '稣', '稳', '稻', '稽', '稿', '穆', '穑', '穗', '穴', '究', '穷', '穹', '空', '穿', '突', '窃', '窄', '窈', '窍', '窑', '窕', '窖', '窗', '窘', '窜', '窝', '窠', '窥', '窦', '窭', '立', '竖', '站', '竞', '竟', '章', '竣', '童', '竭', '端', '竹', '竽', '竿', '笃', '笆', '笊', '笋', '笑', '笔', '笕', '笙', '笛', '笞', '笥', '符', '笨', '第', '笺', '笼', '笾', '等', '筋', '筏', '筐', '筑', '筒', '答', '策', '筚', '筛', '筜', '筝', '筵', '筹', '筼', '签', '简', '箍', '箔', '算', '管', '箦', '箧', '箨', '箩', '箪', '箫', '箭', '箱', '箸', '篆', '篇', '篑', '篓', '篡', '篦', '篮', '篱', '篷', '簇', '簖', '簧', '簪', '簸', '簿', '籁', '籍', '米', '籴', '类', '粉', '粒', '粗', '粘', '粜', '粝', '粟', '粪', '粮', '粳', '粹', '粽', '精', '糁', '糅', '糇', '糊', '糕', '糖', '糗', '糜', '糟', '糠', '糯', '系', '紊', '素', '索', '紧', '紫', '累', '絍', '絮', '絷', '繁', '纂', '纠', '纡', '红', '纣', '纤', '纥', '约', '级', '纨', '纩', '纪', '纫', '纬', '纭', '纮', '纯', '纰', '纱', '纲', '纳', '纴', '纵', '纶', '纷', '纸', '纹', '纺', '纽', '纾', '线', '绀', '绁', '绂', '练', '组', '绅', '细', '织', '终', '绉', '绊', '绋', '绌', '绍', '绎', '经', '绐', '绑', '绒', '结', '绔', '绕', '绗', '绘', '给', '绚', '绛', '络', '绝', '绞', '统', '绠', '绡', '绢', '绣', '绥', '绦', '继', '绨', '绩', '绪', '绫', '续', '绮', '绯', '绰', '绱', '绲', '绳', '维', '绵', '绶', '绷', '绸', '绺', '绻', '综', '绽', '绾', '绿', '缀', '缂', '缃', '缄', '缅', '缆', '缇', '缈', '缉', '缋', '缌', '缎', '缏', '缒', '缓', '缔', '缕', '编', '缗', '缘', '缙', '缚', '缛', '缜', '缝', '缞', '缟', '缠', '缡', '缢', '缣', '缤', '缥', '缦', '缧', '缨', '缩', '缪', '缫', '缬', '缭', '缮', '缯', '缰', '缱', '缲', '缳', '缴', '缵', '缶', '缸', '缺', '罂', '罄', '罐', '网', '罔', '罕', '罗', '罚', '罢', '罩', '罪', '置', '署', '罴', '罹', '羁', '羊', '羌', '美', '羞', '羟', '羡', '群', '羹', '羼', '羽', '翁', '翅', '翔', '翕', '翘', '翚', '翠', '翩', '翰', '翱', '翳', '翻', '翼', '耀', '老', '考', '耄', '者', '而', '耍', '耐', '耕', '耗', '耙', '耞', '耦', '耧', '耳', '耵', '耸', '耻', '耽', '聂', '聆', '聊', '聋', '职', '聍', '联', '聘', '聚', '聩', '聪', '肃', '肄', '肇', '肉', '肋', '肌', '肖', '肘', '肚', '肛', '肝', '肠', '股', '肢', '肤', '肥', '肩', '肭', '肮', '肯', '育', '肴', '肺', '肽', '肾', '肿', '胀', '胁', '胃', '胄', '胆', '背', '胎', '胖', '胚', '胜', '胞', '胠', '胡', '胧', '胨', '胪', '胫', '胭', '胰', '胳', '胴', '胶', '胸', '胺', '能', '脂', '脆', '脉', '脊', '脍', '脏', '脐', '脑', '脓', '脔', '脖', '脚', '脱', '脶', '脸', '脾', '腆', '腈', '腊', '腋', '腌', '腐', '腑', '腔', '腕', '腘', '腥', '腩', '腭', '腮', '腰', '腴', '腹', '腺', '腻', '腼', '腽', '腾', '腿', '膀', '膈', '膏', '膑', '膘', '膛', '膜', '膝', '膨', '膳', '膺', '膻', '臀', '臂', '臃', '臆', '臊', '臌', '臜', '臣', '自', '臭', '至', '致', '臻', '臼', '臾', '舀', '舅', '舆', '舌', '舍', '舒', '舔', '舞', '舟', '舣', '航', '般', '舰', '舱', '舲', '舵', '船', '舻', '艇', '艨', '良', '艰', '色', '艳', '艺', '艻', '艾', '节', '芈', '芋', '芍', '芒', '芜', '芝', '芥', '芦', '芬', '芯', '花', '芲', '芳', '芸', '芽', '苇', '苍', '苏', '苔', '苕', '苗', '苛', '苞', '若', '苦', '苯', '英', '苹', '茁', '茂', '范', '茅', '茈', '茎', '茏', '茑', '茔', '茕', '茧', '茫', '茬', '茵', '茶', '茹', '荆', '草', '荐', '荒', '荔', '荚', '荛', '荜', '荞', '荟', '荠', '荡', '荣', '荤', '荥', '荦', '荧', '荨', '荪', '荫', '荬', '荭', '药', '荷', '荻', '莅', '莓', '莞', '莩', '莫', '莱', '莲', '莳', '莴', '获', '莹', '莺', '莽', '菁', '菇', '菊', '菌', '菔', '菜', '菠', '菱', '菸', '萃', '萌', '萎', '萝', '萤', '营', '萦', '萧', '萨', '萱', '萼', '落', '著', '葛', '葬', '葱', '蒂', '蒇', '蒐', '蒙', '蒜', '蒸', '蒿', '蓄', '蓉', '蓐', '蓑', '蓝', '蓟', '蓣', '蓥', '蓦', '蓬', '蔑', '蔗', '蔚', '蔟', '蔫', '蔬', '蔷', '蔺', '蔼', '蔽', '蕃', '蕊', '蕨', '蕲', '蕴', '蕾', '薄', '薇', '薪', '薮', '薯', '薹', '藉', '藏', '藐', '藓', '藕', '藤', '藩', '藻', '蘖', '蘸', '虎', '虏', '虐', '虑', '虔', '虚', '虞', '虫', '虬', '虮', '虱', '虻', '虽', '虾', '虿', '蚀', '蚁', '蚂', '蚊', '蚕', '蚝', '蚱', '蛀', '蛆', '蛇', '蛊', '蛋', '蛎', '蛔', '蛙', '蛛', '蛟', '蛤', '蛮', '蛰', '蛱', '蛳', '蛴', '蛸', '蛹', '蛾', '蜂', '蜒', '蜕', '蜗', '蜚', '蜜', '蜡', '蜷', '蝀', '蝇', '蝈', '蝉', '蝎', '蝗', '蝙', '蝠', '蝶', '蝼', '蝾', '螂', '融', '螨', '螺', '蟆', '蟊', '蟏', '蟠', '蟥', '蟹', '蠕', '蠖', '蠢', '蠲', '蠹', '血', '衄', '衅', '行', '衍', '衔', '街', '衙', '衡', '衣', '补', '表', '衩', '衬', '衮', '衰', '衷', '衽', '袂', '袄', '袅', '袆', '袋', '袍', '袒', '袖', '袜', '袤', '被', '袭', '袷', '裁', '裂', '装', '裆', '裈', '裔', '裕', '裙', '裢', '裣', '裤', '裥', '裨', '裰', '裸', '裹', '褊', '褒', '褓', '褛', '褡', '褥', '褫', '褴', '褵', '褶', '襕', '襟', '襻', '西', '要', '覆', '见', '观', '规', '觅', '视', '觇', '览', '觉', '觊', '觋', '觌', '觍', '觎', '觏', '觑', '角', '觞', '解', '触', '觯', '言', '訚', '詈', '詟', '誉', '誊', '誓', '警', '计', '订', '讣', '认', '讥', '讦', '讧', '讨', '让', '讪', '讫', '讬', '训', '议', '讯', '记', '讲', '讳', '讴', '讵', '讶', '讷', '许', '讹', '论', '讼', '讽', '设', '访', '诀', '证', '诂', '诃', '评', '诅', '识', '诈', '诉', '诊', '诋', '诌', '词', '诎', '诏', '诐', '译', '诒', '诓', '诔', '试', '诖', '诗', '诘', '诙', '诚', '诛', '诜', '话', '诞', '诟', '诠', '诡', '询', '诣', '诤', '该', '详', '诧', '诨', '诩', '诫', '诬', '语', '诮', '误', '诰', '诱', '诲', '诳', '说', '诵', '诶', '请', '诸', '诹', '诺', '读', '诼', '诽', '课', '诿', '谀', '谁', '谂', '调', '谄', '谅', '谆', '谇', '谈', '谊', '谋', '谌', '谍', '谎', '谏', '谐', '谑', '谒', '谓', '谔', '谕', '谖', '谗', '谘', '谙', '谚', '谛', '谜', '谝', '谟', '谠', '谡', '谢', '谣', '谤', '谥', '谦', '谧', '谨', '谩', '谪', '谫', '谬', '谭', '谮', '谯', '谰', '谱', '谲', '谳', '谴', '谵', '谶', '谷', '豁', '豆', '象', '豢', '豪', '豫', '豸', '豹', '貉', '貌', '贝', '贞', '负', '贠', '贡', '财', '责', '贤', '败', '账', '货', '质', '贩', '贪', '贫', '贬', '购', '贮', '贯', '贰', '贱', '贲', '贳', '贴', '贵', '贶', '贷', '贸', '费', '贺', '贻', '贼', '贽', '贾', '贿', '赀', '赁', '赂', '赃', '资', '赅', '赆', '赇', '赈', '赉', '赊', '赋', '赌', '赍', '赎', '赏', '赐', '赒', '赓', '赔', '赕', '赖', '赘', '赙', '赚', '赛', '赜', '赝', '赞', '赟', '赠', '赡', '赢', '赤', '赦', '赪', '赫', '走', '赴', '赵', '赶', '起', '趁', '超', '越', '趋', '趟', '趣', '趱', '足', '趸', '趺', '趾', '跃', '跄', '跋', '跌', '跑', '跚', '跛', '距', '跞', '跟', '跤', '跨', '跪', '路', '跳', '践', '跶', '跷', '跸', '跹', '跺', '跻', '踉', '踊', '踌', '踏', '踝', '踞', '踟', '踣', '踩', '踪', '踬', '踮', '踯', '蹀', '蹂', '蹄', '蹇', '蹑', '蹒', '蹙', '蹚', '蹦', '蹩', '蹬', '蹰', '蹲', '蹴', '蹼', '蹿', '躁', '躅', '躇', '躏', '躗', '躜', '身', '躬', '躯', '躲', '躺', '輂', '轗', '车', '轧', '轨', '轩', '轫', '转', '轭', '轮', '软', '轰', '轱', '轲', '轳', '轴', '轵', '轶', '轸', '轹', '轺', '轻', '轼', '载', '轾', '轿', '辁', '辂', '较', '辄', '辅', '辆', '辇', '辈', '辉', '辊', '辋', '辍', '辎', '辏', '辐', '辑', '辒', '输', '辔', '辕', '辖', '辗', '辘', '辙', '辚', '辛', '辜', '辞', '辟', '辣', '辨', '辩', '辫', '辰', '辱', '边', '辽', '达', '迁', '迂', '过', '迈', '迎', '运', '近', '返', '还', '这', '进', '远', '违', '连', '迟', '迤', '迥', '迩', '迪', '迫', '迭', '迮', '述', '迳', '迷', '迸', '迹', '追', '退', '送', '适', '逃', '逆', '选', '逊', '逍', '透', '逐', '递', '途', '逗', '通', '逛', '逝', '逞', '速', '造', '逢', '逦', '逸', '逻', '逼', '逾', '遁', '遂', '遇', '遍', '遐', '遑', '道', '遗', '遛', '遝', '遣', '遥', '遨', '遭', '遮', '遴', '遵', '遽', '避', '邀', '邃', '邈', '邑', '那', '邦', '邪', '邮', '邸', '邻', '郁', '郊', '郎', '郑', '郓', '郡', '郧', '部', '都', '鄙', '酉', '酌', '配', '酒', '酗', '酝', '酣', '酥', '酦', '酪', '酬', '酮', '酯', '酱', '酵', '酶', '酷', '酸', '酽', '酾', '酿', '醇', '醉', '醋', '醒', '醣', '采', '释', '里', '重', '野', '量', '金', '鉴', '銮', '錾', '鏖', '钆', '钇', '针', '钉', '钊', '钋', '钌', '钍', '钎', '钏', '钐', '钒', '钓', '钔', '钕', '钗', '钙', '钚', '钛', '钜', '钝', '钞', '钟', '钠', '钡', '钢', '钣', '钤', '钥', '钦', '钧', '钨', '钩', '钪', '钫', '钬', '钭', '钮', '钯', '钰', '钱', '钲', '钳', '钴', '钵', '钶', '钷', '钸', '钹', '钺', '钻', '钼', '钽', '钾', '钿', '铀', '铁', '铂', '铃', '铄', '铅', '铆', '铇', '铈', '铊', '铋', '铌', '铍', '铎', '铐', '铑', '铒', '铓', '铔', '铕', '铖', '铗', '铙', '铛', '铜', '铝', '铟', '铠', '铡', '铢', '铣', '铤', '铥', '铦', '铧', '铨', '铩', '铪', '铫', '铬', '铭', '铮', '铯', '铰', '铱', '铲', '铳', '铵', '银', '铷', '铸', '铹', '铺', '铼', '铽', '链', '铿', '销', '锁', '锂', '锃', '锄', '锅', '锆', '锇', '锈', '锉', '锊', '锋', '锌', '锎', '锏', '锐', '锑', '锒', '锓', '锔', '锕', '锖', '锗', '锘', '错', '锚', '锛', '锜', '锝', '锞', '锟', '锡', '锢', '锣', '锤', '锥', '锦', '锨', '锩', '锫', '锬', '锭', '键', '锯', '锰', '锱', '锲', '锴', '锵', '锶', '锷', '锸', '锹', '锺', '锻', '锼', '锽', '锾', '锿', '镀', '镁', '镂', '镃', '镄', '镅', '镆', '镇', '镈', '镉', '镊', '镌', '镍', '镎', '镏', '镐', '镑', '镒', '镓', '镔', '镕', '镖', '镗', '镘', '镚', '镛', '镜', '镝', '镞', '镟', '镠', '镡', '镢', '镣', '镤', '镥', '镦', '镧', '镨', '镪', '镫', '镬', '镭', '镯', '镰', '镱', '镲', '镳', '镴', '镶', '长', '门', '闩', '闪', '闬', '闭', '问', '闯', '闰', '闱', '闲', '闳', '间', '闵', '闶', '闷', '闸', '闹', '闺', '闻', '闼', '闾', '闿', '阀', '阁', '阂', '阃', '阄', '阅', '阆', '阇', '阈', '阉', '阊', '阋', '阍', '阏', '阐', '阑', '阒', '阔', '阕', '阖', '阗', '阙', '阚', '阜', '队', '阢', '阱', '防', '阳', '阴', '阵', '阶', '阻', '阿', '陀', '附', '际', '陆', '陈', '陉', '陋', '陌', '降', '限', '陡', '院', '除', '陧', '陨', '险', '陪', '陲', '陵', '陶', '陷', '隆', '隋', '随', '隐', '隔', '隘', '隙', '障', '隶', '隼', '隽', '难', '雀', '雁', '雄', '雅', '集', '雇', '雉', '雌', '雍', '雏', '雕', '雠', '雨', '雪', '雳', '零', '雷', '雹', '雾', '需', '霁', '霄', '震', '霉', '霍', '霎', '霜', '霞', '霭', '露', '霸', '霹', '霾', '青', '靓', '靔', '靖', '静', '靛', '非', '靠', '靡', '面', '靥', '革', '靪', '靴', '靶', '鞋', '鞍', '鞣', '鞭', '鞯', '韦', '韧', '韩', '韪', '韫', '韬', '韭', '音', '韵', '页', '顶', '顷', '顸', '项', '顺', '须', '顼', '顽', '顾', '顿', '颀', '颁', '颂', '颃', '预', '颅', '领', '颇', '颈', '颉', '颊', '颌', '颍', '颎', '颏', '颐', '频', '颓', '颔', '颕', '颖', '颗', '题', '颙', '颚', '颛', '颜', '额', '颞', '颟', '颠', '颡', '颢', '颤', '颥', '颦', '颧', '风', '飏', '飐', '飑', '飒', '飓', '飕', '飖', '飘', '飙', '飚', '飞', '食', '飧', '飨', '餍', '餐', '饔', '饤', '饥', '饧', '饩', '饪', '饫', '饬', '饭', '饮', '饯', '饰', '饱', '饲', '饴', '饵', '饶', '饷', '饸', '饹', '饺', '饼', '饽', '饿', '馀', '馁', '馂', '馃', '馄', '馅', '馆', '馈', '馊', '馋', '馌', '馍', '馎', '馏', '馐', '馑', '馒', '馓', '馔', '馕', '首', '香', '馥', '馨', '马', '驭', '驮', '驯', '驰', '驱', '驳', '驴', '驵', '驶', '驷', '驸', '驹', '驺', '驻', '驼', '驽', '驾', '驿', '骀', '骁', '骂', '骃', '骄', '骅', '骆', '骇', '骈', '骊', '骋', '验', '骎', '骏', '骐', '骑', '骒', '骓', '骖', '骗', '骘', '骚', '骛', '骜', '骝', '骞', '骟', '骠', '骡', '骢', '骣', '骤', '骥', '骧', '骨', '骰', '骷', '骸', '髂', '髅', '髇', '髋', '髌', '髓', '高', '髦', '髭', '髯', '髻', '鬃', '鬓', '鬼', '魁', '魂', '魄', '魇', '魉', '魍', '魔', '魣', '鱆', '鱼', '鱿', '鲁', '鲃', '鲅', '鲆', '鲈', '鲋', '鲍', '鲎', '鲏', '鲑', '鲒', '鲔', '鲕', '鲗', '鲘', '鲛', '鲜', '鲞', '鲟', '鲠', '鲡', '鲢', '鲣', '鲤', '鲨', '鲩', '鲫', '鲭', '鲮', '鲰', '鲱', '鲳', '鲶', '鲷', '鲸', '鲻', '鲼', '鲽', '鳀', '鳁', '鳃', '鳄', '鳅', '鳇', '鳊', '鳌', '鳍', '鳎', '鳏', '鳑', '鳔', '鳕', '鳖', '鳗', '鳙', '鳝', '鳞', '鳟', '鳠', '鳢', '鳣', '鸟', '鸠', '鸡', '鸢', '鸣', '鸤', '鸥', '鸦', '鸧', '鸨', '鸩', '鸪', '鸫', '鸬', '鸭', '鸮', '鸯', '鸰', '鸱', '鸲', '鸳', '鸴', '鸵', '鸶', '鸷', '鸸', '鸹', '鸺', '鸻', '鸽', '鸾', '鸿', '鹁', '鹃', '鹄', '鹅', '鹆', '鹇', '鹈', '鹉', '鹊', '鹋', '鹌', '鹍', '鹏', '鹑', '鹒', '鹕', '鹖', '鹗', '鹘', '鹙', '鹚', '鹜', '鹞', '鹡', '鹣', '鹤', '鹦', '鹧', '鹩', '鹪', '鹫', '鹬', '鹭', '鹰', '鹳', '鹾', '鹿', '麈', '麟', '麦', '麸', '麻', '麽', '黄', '黉', '黏', '黐', '黑', '默', '黜', '黩', '黪', '黯', '黾', '鼋', '鼎', '鼓', '鼠', '鼢', '鼬', '鼹', '鼻', '鼾', '齐', '齑', '齿', '龀', '龃', '龄', '龅', '龆', '龇', '龈', '龉', '龊', '龋', '龌', '龙', '龛', '龟']\n",
      "episode: 0\n",
      "sh: processing \"write\" data from /home/xavier/oteann4/subdatasets/sh_wikt_samples.csv\n",
      "                   Word      Pronunciation\n",
      "71368  resocijalizirati  resotsijalizirati\n",
      "45716        nabreknuće        nabreknutɕe\n",
      "14433        dopisivati         dopisiʋati\n",
      "49615          neuvijen           neuʋijen\n",
      "5592           bekasina           bekasina\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sh: processing \"read\" data from /home/xavier/oteann4/subdatasets/sh_wikt_samples.csv\n",
      "                 Word   Pronunciation\n",
      "7830              bok             bok\n",
      "26977       indološki       indoloʃki\n",
      "40856   lužičkosrpski  luʒitʃkosrpski\n",
      "94720           čerga          tʃerɡa\n",
      "73328  samopoštovanje   samopoʃtoʋaɲe\n",
      "config['train_filename']: /home/xavier/oteann4/oteann_11000_train.csv\n",
      "data has 501488 characters, 5109 unique.\n",
      "ANN parameters: 9585312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1959 [00:00<?, ?it/s]/home/xavier/oteann4/oteann4/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "epoch 1 iter 1958: train loss 0.73976. lr 3.000764e-04: 100%|██████████| 1959/1959 [03:28<00:00,  9.40it/s]\n",
      "epoch 2 iter 1958: train loss 0.60756. lr 6.000000e-05: 100%|██████████| 1959/1959 [03:25<00:00,  9.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_duration 0:06:59.078657\n",
      "sh write: n=1000, n_ok=983, n_ko=17 => %n_ok=98%\n",
      "sh  read: n=1000, n_ok=985, n_ko=15 => %n_ok=98%\n",
      "accuracy:0.98\n"
     ]
    }
   ],
   "source": [
    "df_results = main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lang</th>\n",
       "      <th>task</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>test_duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sh</td>\n",
       "      <td>write</td>\n",
       "      <td>0.983</td>\n",
       "      <td>0 days 00:00:56.097295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sh</td>\n",
       "      <td>read</td>\n",
       "      <td>0.985</td>\n",
       "      <td>0 days 00:00:56.163116</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  lang   task  test_accuracy          test_duration\n",
       "0   sh  write          0.983 0 days 00:00:56.097295\n",
       "1   sh   read          0.985 0 days 00:00:56.163116"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
